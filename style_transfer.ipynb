{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style_transfer",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agrawalsourabh/DeepLearning/blob/master/style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcjjB3jLHv6Z",
        "colab_type": "text"
      },
      "source": [
        "# IMAGE STYLE TRANSFER\n",
        "\n",
        "**Description**</br>\n",
        "Content Image + Style Image = Generated Image </br>\n",
        "Research Paper: [Image Style Transfer Using CNN](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf)\n",
        "</br>\n",
        "\n",
        "**Learning Objectives:** </br>\n",
        "\n",
        "* Deep understanding on Convolution Neural Networks.\n",
        "* Calculate Loss functions.\n",
        "* Load the VGG16 model.\n",
        "* Tuning Hyper Parameters.\n",
        "* Deploy the model in browser.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECDCAKUxJzM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "import tensorflow as tf\n",
        "from scipy.optimize import fmin_l_bfgs_b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrfKsxzZKjrI",
        "colab_type": "text"
      },
      "source": [
        "**Define Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il5K4AykKvWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ITERATIONS = 10\n",
        "CHANNELS = 3\n",
        "IMAGE_SIZE = 500\n",
        "IMAGE_WIDTH = IMAGE_SIZE\n",
        "IMAGE_HEIGHT = IMAGE_SIZE\n",
        "IMAGENET_MEAN_RGB_VALUES = [123.68, 116.779, 103.939]\n",
        "CONTENT_WEIGHT = 0.02\n",
        "STYLE_WEIGHT = 4.5\n",
        "TOTAL_VARIATION_WEIGHT = 0.995\n",
        "TOTAL_VARIATION_LOSS_FACTOR = 1.25\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7t3rdK_LgPX",
        "colab_type": "text"
      },
      "source": [
        "**Image Paths**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aqU3dPfLjle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_image_path = \"input.png\"\n",
        "style_image_path = \"style.png\"\n",
        "output_image_path = \"output.png\"\n",
        "combine_image_path = \"combined.png\"\n",
        "\n",
        "# Content Image - San Francisco\n",
        "san_francisco_img_path = \"https://www.economist.com/sites/default/files/images/print-edition/20180602_USP001_0.jpg\"\n",
        "\n",
        "# Style Image\n",
        "tytus_image_path = \"http://meetingbenches.com/wp-content/flagallery/tytus-brzozowski-polish-architect-and-watercolorist-a-fairy-tale-in-warsaw/tytus_brzozowski_13.jpg\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpeIiwvCMYMm",
        "colab_type": "text"
      },
      "source": [
        "**Image Visualisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3iCwsVwMa58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_image = Image.open(BytesIO(requests.get(san_francisco_img_path).content))\n",
        "print(\"Original Image size\", input_image.size)\n",
        "\n",
        "# Resize the image to 500 X 500\n",
        "input_image = input_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n",
        "print(\"Original Image size\", input_image.size)\n",
        "\n",
        "input_image.save(input_image_path)\n",
        "\n",
        "input_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46xEkq9bOLFs",
        "colab_type": "text"
      },
      "source": [
        "**Style Visualisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlfMI2yhOcwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_image = Image.open(BytesIO(requests.get(tytus_image_path).content))\n",
        "print(\"Original image size: \", style_image.size)\n",
        "\n",
        "# Resize image to 500 X 500\n",
        "style_image = style_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT));\n",
        "print(\"After resizing image size: \", style_image.size)\n",
        "\n",
        "# save style image\n",
        "style_image.save(style_image_path)\n",
        "\n",
        "style_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym7NNNKmQVws",
        "colab_type": "text"
      },
      "source": [
        "**Data Normalisation and reshaping to RGB to BGR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqKdkgN4RqOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input image\n",
        "input_image_array = np.asarray(input_image, dtype = \"float32\")\n",
        "print(input_image_array)\n",
        "\n",
        "input_image_array = np.expand_dims(input_image_array, axis=0)\n",
        "print(\"After expand dims: \", input_image_array)\n",
        "\n",
        "input_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\n",
        "input_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n",
        "input_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n",
        "input_image_array = input_image_array[:, :, :, ::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8a4elRKc3WQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# style_image\n",
        "style_image_array = np.asarray(style_image, dtype=\"float32\")\n",
        "style_image_array = np.expand_dims(style_image_array, axis=0)\n",
        "style_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\n",
        "style_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n",
        "style_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n",
        "style_image_array = style_image_array[:, :, :, ::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxqkc6dPc-bc",
        "colab_type": "text"
      },
      "source": [
        "**Load the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItU0Y4AodBlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input image\n",
        "input_image = tf.keras.backend.variable(input_image_array)\n",
        "input_image\n",
        "\n",
        "# output image\n",
        "style_image = tf.keras.backend.variable(style_image_array)\n",
        "style_image\n",
        "\n",
        "# combination image\n",
        "combination_image = tf.keras.backend.placeholder((1, IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
        "combination_image\n",
        "\n",
        "# concatenate these two images\n",
        "input_tensor = tf.keras.backend.concatenate([input_image, style_image, combination_image], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R_i5x5Xfgy4",
        "colab_type": "text"
      },
      "source": [
        "**Load VGG19 Model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mhru9kbfmay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.applications.vgg16.VGG16(input_tensor = input_tensor, include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20QAJetWf5se",
        "colab_type": "text"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4v_rUyvf9k0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpAgg52ZgTMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def content_loss(content, combination):\n",
        "    return tf.keras.backend.sum(tf.keras.backend.square(combination - content))\n",
        "\n",
        "layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "\n",
        "content_layer = \"block2_conv2\"\n",
        "layer_features = layers[content_layer]\n",
        "content_image_features = layer_features[0, :, :, :]\n",
        "combination_features = layer_features[2, :, :, :]\n",
        "\n",
        "loss = tf.keras.backend.variable(0.)\n",
        "loss = loss+  CONTENT_WEIGHT * content_loss(content_image_features,\n",
        "                                      combination_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVOxSCMCgyvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gram_matrix(x):\n",
        "    features = tf.keras.backend.batch_flatten(tf.keras.backend.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = tf.keras.backend.dot(features, tf.keras.backend.transpose(features))\n",
        "    return gram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRr-aTRPg7qD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_style_loss(style, combination):\n",
        "    style = gram_matrix(style)\n",
        "    combination = gram_matrix(combination)\n",
        "    size = IMAGE_HEIGHT * IMAGE_WIDTH\n",
        "    return tf.keras.backend.sum(tf.keras.backend.square(style - combination)) / (4. * (CHANNELS ** 2) * (size ** 2))\n",
        "\n",
        "style_layers = [\"block1_conv2\", \"block2_conv2\", \"block3_conv3\", \"block4_conv3\", \"block5_conv3\"]\n",
        "for layer_name in style_layers:\n",
        "    layer_features = layers[layer_name]\n",
        "    style_features = layer_features[1, :, :, :]\n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    style_loss = compute_style_loss(style_features, combination_features)\n",
        "    loss = loss + (STYLE_WEIGHT / len(style_layers)) * style_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-N-oCodhU6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def total_variation_loss(x):\n",
        "    a = tf.keras.backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, 1:, :IMAGE_WIDTH-1, :])\n",
        "    b = tf.keras.backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, :IMAGE_HEIGHT-1, 1:, :])\n",
        "    return tf.keras.backend.sum(tf.keras.backend.pow(a + b, TOTAL_VARIATION_LOSS_FACTOR))\n",
        "\n",
        "loss = loss + TOTAL_VARIATION_WEIGHT * total_variation_loss(combination_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H73g9yZghvP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = [loss]\n",
        "outputs = outputs + tf.keras.backend.gradients(loss, combination_image)\n",
        "\n",
        "def evaluate_loss_and_gradients(x):\n",
        "    x = x.reshape((1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
        "    outs = tf.keras.backend.function([combination_image], outputs)([x])\n",
        "    loss = outs[0]\n",
        "    gradients = outs[1].flatten().astype(\"float64\")\n",
        "    return loss, gradients\n",
        "\n",
        "class Evaluator:\n",
        "\n",
        "    def loss(self, x):\n",
        "        loss, gradients = evaluate_loss_and_gradients(x)\n",
        "        self._gradients = gradients\n",
        "        return loss\n",
        "\n",
        "    def gradients(self, x):\n",
        "        return self._gradients\n",
        "\n",
        "evaluator = Evaluator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIu2og2ah5T3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.random.uniform(0, 255, (1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)) - 128.\n",
        "\n",
        "for i in range(ITERATIONS):\n",
        "    x, loss, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.gradients, maxfun=20)\n",
        "    print(\"Iteration %d completed with loss %d\" % (i, loss))\n",
        "    \n",
        "x = x.reshape((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
        "x = x[:, :, ::-1]\n",
        "x[:, :, 0] = x[:, :, 0] + IMAGENET_MEAN_RGB_VALUES[2]\n",
        "x[:, :, 1] = x[:, :, 1] + IMAGENET_MEAN_RGB_VALUES[1]\n",
        "x[:, :, 2] = x[:, :, 2] + IMAGENET_MEAN_RGB_VALUES[0]\n",
        "x = np.clip(x, 0, 255).astype(\"uint8\")\n",
        "output_image = Image.fromarray(x)\n",
        "output_image.save(output_image_path)\n",
        "output_image"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}