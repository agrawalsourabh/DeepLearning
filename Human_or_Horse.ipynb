{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Human-or-Horse",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agrawalsourabh/DeepLearning/blob/master/Human_or_Horse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMAZTQ7Bgjj-",
        "colab_type": "text"
      },
      "source": [
        "# Human - or - Horse</br>\n",
        "Built a model that classify the image as Horse image or Human image.\n",
        "</br>\n",
        "\n",
        "**Learning Objective:**\n",
        "* Download the data to local drive.\n",
        "* Configure a neural network model\n",
        "* Built the model.\n",
        "* Tweak the hyperparameters to increase accuracy.\n",
        "* Configure other NN model.\n",
        "* Deploy the model to andorid app."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjUBP5xuhawc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the public image dataset\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n",
        "    -O /tmp/horse-or-human.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8KK1uMLhuIC",
        "colab_type": "text"
      },
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThHAK4xrh1zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = \"/tmp/horse-or-human.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "zip_ref.extractall('/tmp/horse-or-human')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLAsfRU1i6vW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory with our training horse picture\n",
        "train_horse_dir = os.path.join('/tmp/horse-or-human/horses')\n",
        "\n",
        "# Directory with our training human picture\n",
        "train_human_dir = os.path.join('/tmp/horse-or-human/humans')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmonuv0Qjhnw",
        "colab_type": "text"
      },
      "source": [
        "Let's see how the file names look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5q-yz2qjl7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Horse images - \")\n",
        "train_horse_image = os.listdir(train_horse_dir)\n",
        "print(train_horse_image[:10])\n",
        "\n",
        "print(\"Human images - \")\n",
        "train_human_image = os.listdir(train_human_dir)\n",
        "print(train_human_image[:10])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo1HpQlEkny9",
        "colab_type": "text"
      },
      "source": [
        "Check total training horse and human images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQPEnmFMkuGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Total human images: ', len(os.listdir(train_human_dir)))\n",
        "print('Total horse images: ', len(os.listdir(train_horse_dir)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARdRNwRWlK8w",
        "colab_type": "text"
      },
      "source": [
        "**Visualise training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzextkIylO_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "# Setup plot size\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "\n",
        "# Horse Images\n",
        "sbplt_index = 0\n",
        "for horse_fname in train_horse_image[:4] :\n",
        "  \n",
        "  sbplt_index = sbplt_index + 1\n",
        "  \n",
        "  horse_fileName = os.path.join(train_horse_dir, horse_fname)\n",
        "  \n",
        "  sp = plt.subplot(nrows, ncols, sbplt_index)\n",
        "  sp.axis('Off')\n",
        "  \n",
        "  horse_img = mpimg.imread(horse_fileName)\n",
        "  plt.imshow(horse_img)\n",
        "  \n",
        "  \n",
        "  \n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Setup plot size\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "# Human Images\n",
        "sbplt_index = 0\n",
        "for human_fname in train_human_image[:4] :\n",
        "  sbplt_index = sbplt_index +1\n",
        "  human_fileName = os.path.join(train_human_dir, human_fname)\n",
        "  \n",
        "  sp = plt.subplot(nrows, ncols, sbplt_index)\n",
        "  sp.axis('Off')\n",
        "  \n",
        "  human_img = mpimg.imread(human_fileName)\n",
        "  plt.imshow(human_img)\n",
        "  \n",
        "plt.show()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaxTk6iXuNIn",
        "colab_type": "text"
      },
      "source": [
        "**Build a model from Scratch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzhCqQAyuSUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KErrJp3uuYAx",
        "colab_type": "text"
      },
      "source": [
        "**Configure a model**\n",
        "* Sequence\n",
        "* Conv - 1st layer\n",
        "* Max pooling\n",
        "* Conv - 2nd layer\n",
        "* Max pooling\n",
        "* Flatten\n",
        "* Fully Connected layer\n",
        "* Output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZOTM_yVuzpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# 1st Conv layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), \n",
        "                                 activation='relu', input_shape=(300, 300, 3)))\n",
        "# Max pooling\n",
        "model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "\n",
        "\n",
        "# 2nd Conv layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), \n",
        "                                 activation='relu'))\n",
        "# Max pooling\n",
        "model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "\n",
        "# Flatten\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Hidden layer - with 512 neurons\n",
        "model.add(tf.keras.layers.Dense(512, activation=\"relu\"))\n",
        "\n",
        "# Output layer - with only one neuron\n",
        "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCpjXuZ6xCOf",
        "colab_type": "text"
      },
      "source": [
        "model.summary() prints the summary of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMSt5HqyxHtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu96NXaBysMz",
        "colab_type": "text"
      },
      "source": [
        "**Complile the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lOBuEURyvIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r4vKzsBzIx9",
        "colab_type": "text"
      },
      "source": [
        "**Data Preprocessing**\n",
        "We'll use data generator form Keras.Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JEYqCd4zae6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# all images will be rescaled by /255\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/tmp/horse-or-human/',  # This is the source directory for training images\n",
        "        target_size=(300, 300),  # All images will be resized to 150x150\n",
        "        batch_size=128,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYIcTMSx1As4",
        "colab_type": "text"
      },
      "source": [
        "**Training Model**\n",
        "Let's train the model for 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfHfpk_K1KfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=8,  \n",
        "      epochs=15,\n",
        "      verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98-0HDCW335X",
        "colab_type": "text"
      },
      "source": [
        "**Predict using local image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dyjn2kK3xEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(300, 300))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a human\")\n",
        "  else:\n",
        "    print(fn + \" is a horse\")\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}